{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11913321,"sourceType":"datasetVersion","datasetId":7489704}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-22T20:41:57.473864Z","iopub.execute_input":"2025-05-22T20:41:57.474206Z","iopub.status.idle":"2025-05-22T20:41:57.851375Z","shell.execute_reply.started":"2025-05-22T20:41:57.474180Z","shell.execute_reply":"2025-05-22T20:41:57.850525Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/vertex-service-sa/peppy-appliance-460613-k3-cc10f0749a25.json\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Semantic Search with Vertex AI Embeddings and FAISS on NFCorpus","metadata":{}},{"cell_type":"markdown","source":"## Overview\n\nIn this notebook, we will build a simple semantic search using Vertex AI's text embedding models and FAISS for semantic search.\n\nWe are using NFCCourpus Dataset.","metadata":{}},{"cell_type":"markdown","source":"## **Steps:**\n- Setup the libraries\n- Load the NFCourpus Dataset\n- Vertex AI to laoad a pre trained model for text embedding.\n- Convert documents into embeddings and build a FAISS index for fast searching.\n- Sample Test\n- Evaluation using pytrec_eval","metadata":{}},{"cell_type":"code","source":"!pip install --quiet beir faiss-cpu google-cloud-aiplatform numpy pandas pytrec_eval","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T20:42:11.333978Z","iopub.execute_input":"2025-05-22T20:42:11.334371Z","iopub.status.idle":"2025-05-22T20:43:50.139556Z","shell.execute_reply.started":"2025-05-22T20:42:11.334349Z","shell.execute_reply":"2025-05-22T20:43:50.138161Z"}},"outputs":[{"name":"stdout","text":"  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.7/70.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.0/288.0 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m78.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Building wheel for pytrec_eval (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"#beir -> benchmarking Information retrieval. Benchmark framework designed to evaluate the performance of IR models across diverse tasks and dataset.\n#pytech_eval is python interface to trev_eval toolkit, which is a standard tool for evaluating IR systems.\n\nfrom beir import util\nfrom beir.datasets.data_loader import GenericDataLoader\nimport faiss\nimport vertexai\nfrom vertexai.language_models import TextEmbeddingInput, TextEmbeddingModel\nimport numpy as np\nimport pandas as pd\nimport pytrec_eval","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T20:43:50.141937Z","iopub.execute_input":"2025-05-22T20:43:50.142347Z","iopub.status.idle":"2025-05-22T20:44:16.110101Z","shell.execute_reply.started":"2025-05-22T20:43:50.142300Z","shell.execute_reply":"2025-05-22T20:44:16.109201Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/beir/util.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n  from tqdm.autonotebook import tqdm\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"#This function will take textual strings and convert them into their numerical embeddings using Vertex AI model.\n#We will be able to use it anywhere for embedding large corpus of data or incoming queries.\n\ndef embed_text(texts: list[str], model: TextEmbeddingModel, task: str, batch_size: int = 5) -> np.ndarray:\n    \"\"\"\n    Embeds a list of texts using a Vertex AI embedding model.\n\n    Args:\n        texts: A list of strings to embed.\n        model: The Vertex AI TextEmbeddingModel instance.\n        task: The task type for the embedding (e.g., \"RETRIEVAL_DOCUMENT\", \"RETRIEVAL_QUERY\").\n        batch_size: The number of texts to process in each batch.\n\n    Returns:\n        A NumPy array containing the embeddings.\n    \"\"\"\n    embed_mat = np.zeros((len(texts), 768))  # Assuming 768 dimensions for \"text-embedding-005\"\n    for batch_start in range(0, len(texts), batch_size):\n        size = min(len(texts) - batch_start, batch_size)\n\n        #Vertex AI SDK method doesn't take a list of raw strings, it expects TextEmbeddingInput objects.\n        #Each of these objects needs the text and a task_type.\n        inputs = [TextEmbeddingInput(texts[batch_start + i], task_type=task) for i in range(size)]\n        embeddings = model.get_embeddings(inputs)\n        for i in range(size):\n            embed_mat[batch_start + i, :] = embeddings[i].values\n    return embed_mat","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T20:44:16.110903Z","iopub.execute_input":"2025-05-22T20:44:16.111406Z","iopub.status.idle":"2025-05-22T20:44:16.118433Z","shell.execute_reply.started":"2025-05-22T20:44:16.111382Z","shell.execute_reply":"2025-05-22T20:44:16.117510Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## Loading NFCorpus dataset.\nIt contains corpus of medical documents, a set of queries, and relevance judgments (qrels)\n","metadata":{}},{"cell_type":"code","source":"url = \"https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/nfcorpus.zip\"\ndata_path_root = \"datasets\" # Root directory for datasets\ndata_path_nfcorpus = os.path.join(data_path_root, \"nfcorpus\") # Specific path for nfcorpus","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T20:44:16.120463Z","iopub.execute_input":"2025-05-22T20:44:16.120815Z","iopub.status.idle":"2025-05-22T20:44:16.147617Z","shell.execute_reply.started":"2025-05-22T20:44:16.120787Z","shell.execute_reply":"2025-05-22T20:44:16.146705Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Create the datasets directory if it doesn't exist\nos.makedirs(data_path_root, exist_ok=True)\n\ndownloaded_data_path = util.download_and_unzip(url, data_path_root)\nprint(f\"Dataset downloaded and unzipped to: {downloaded_data_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T20:44:16.148544Z","iopub.execute_input":"2025-05-22T20:44:16.148805Z","iopub.status.idle":"2025-05-22T20:44:16.386537Z","shell.execute_reply.started":"2025-05-22T20:44:16.148784Z","shell.execute_reply":"2025-05-22T20:44:16.385841Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"datasets/nfcorpus.zip:   0%|          | 0.00/2.34M [00:00<?, ?iB/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df72da53599c4f649a69fe9095dbcd58"}},"metadata":{}},{"name":"stdout","text":"Dataset downloaded and unzipped to: datasets/nfcorpus\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Load the corpus, queries, and qrels for the \"test\" split\ncorpus, queries, qrels = GenericDataLoader(data_folder=downloaded_data_path).load(split=\"test\")\n\nprint(f\"Number of documents: {len(corpus)}\")\nprint(f\"Number of queries: {len(queries)}\")\nprint(f\"Number of query-relevance pairs: {sum(len(v) for v in qrels.values())}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T20:44:16.387486Z","iopub.execute_input":"2025-05-22T20:44:16.387765Z","iopub.status.idle":"2025-05-22T20:44:16.479641Z","shell.execute_reply.started":"2025-05-22T20:44:16.387743Z","shell.execute_reply":"2025-05-22T20:44:16.478917Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3633 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a8b7d8db8d74a899ba49a26a161adba"}},"metadata":{}},{"name":"stdout","text":"Number of documents: 3633\nNumber of queries: 323\nNumber of query-relevance pairs: 12334\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"#Example\ndoc_id_example, doc_example = next(iter(corpus.items()))\nquery_id_example, query_example = next(iter(queries.items()))\nprint(f\"\\nExample Document (ID: {doc_id_example}): '{doc_example['title']} {doc_example['text'][:100]}...'\")\nprint(f\"Example Query (ID: {query_id_example}): '{query_example}'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T20:44:16.481028Z","iopub.execute_input":"2025-05-22T20:44:16.481400Z","iopub.status.idle":"2025-05-22T20:44:17.154550Z","shell.execute_reply.started":"2025-05-22T20:44:16.481365Z","shell.execute_reply":"2025-05-22T20:44:17.153515Z"}},"outputs":[{"name":"stdout","text":"\nExample Document (ID: MED-10): 'Statin Use and Breast Cancer Survival: A Nationwide Cohort Study from Finland Recent studies have suggested that statins, an established drug group in the prevention of cardiovas...'\nExample Query (ID: PLAIN-2): 'Do Cholesterol Statin Drugs Cause Breast Cancer?'\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"!pip install -q --upgrade vertexai google-genai","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T20:44:17.155548Z","iopub.execute_input":"2025-05-22T20:44:17.155892Z","iopub.status.idle":"2025-05-22T20:44:43.931593Z","shell.execute_reply.started":"2025-05-22T20:44:17.155856Z","shell.execute_reply":"2025-05-22T20:44:43.930399Z"}},"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: google-cloud-aiplatform 1.71.1 does not provide the extra 'all'\u001b[0m\u001b[33m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m80.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.3/196.3 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# ------------------ This is to be hidden ------------------ #\n#PROJECT_ID = \"Added as kaggle Secret\"\n#LOCATION = \"Added as Kaggle Secret\"   \n# -----------------------------------------------------------","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T20:44:43.932901Z","iopub.execute_input":"2025-05-22T20:44:43.933266Z","iopub.status.idle":"2025-05-22T20:44:43.938102Z","shell.execute_reply.started":"2025-05-22T20:44:43.933225Z","shell.execute_reply":"2025-05-22T20:44:43.937368Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"import os\nos.makedirs(\"Google_Service_key\", exist_ok=True)\nos.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/kaggle/input/vertex-service-sa/peppy-appliance-460613-k3-cc10f0749a25.json\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T20:44:43.940900Z","iopub.execute_input":"2025-05-22T20:44:43.941242Z","iopub.status.idle":"2025-05-22T20:44:43.957283Z","shell.execute_reply.started":"2025-05-22T20:44:43.941212Z","shell.execute_reply":"2025-05-22T20:44:43.956225Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\n\nPROJECT_ID = UserSecretsClient().get_secret(\"PROJECT_ID\")\nLOCATION = UserSecretsClient().get_secret(\"LOCATION\")\n\nvertexai.init(project=PROJECT_ID, location=LOCATION)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T20:46:26.118037Z","iopub.execute_input":"2025-05-22T20:46:26.119092Z","iopub.status.idle":"2025-05-22T20:46:26.503067Z","shell.execute_reply.started":"2025-05-22T20:46:26.119048Z","shell.execute_reply":"2025-05-22T20:46:26.502121Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"#Loading the model for embedding\nmodel_name = \"text-embedding-005\" #It has 768 dimensions\nmodel = TextEmbeddingModel.from_pretrained(model_name)\nprint(f\"Loaded Vertex AI embedding model: {model_name}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T20:47:23.413585Z","iopub.execute_input":"2025-05-22T20:47:23.414673Z","iopub.status.idle":"2025-05-22T20:47:25.453467Z","shell.execute_reply.started":"2025-05-22T20:47:23.414616Z","shell.execute_reply":"2025-05-22T20:47:25.452431Z"}},"outputs":[{"name":"stdout","text":"Loaded Vertex AI embedding model: text-embedding-005\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"#corpus.items()\n\n#zip and '*', the unpacking operator takes the list of tuples and \"unzips\" them into two separate tuples.\ndoc_ids, docs = zip(*[(doc_id, doc['text']) for doc_id, doc in corpus.items()])\nprint(f\"Prepared {len(docs)} documents for embedding.\")\n\n# Extract query IDs and texts\nq_ids, questions = zip(*[(q_id, q_text) for q_id, q_text in queries.items()])\nprint(f\"Prepared {len(questions)} queries for embedding.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T20:47:27.223737Z","iopub.execute_input":"2025-05-22T20:47:27.224091Z","iopub.status.idle":"2025-05-22T20:47:27.239753Z","shell.execute_reply.started":"2025-05-22T20:47:27.224066Z","shell.execute_reply":"2025-05-22T20:47:27.238889Z"}},"outputs":[{"name":"stdout","text":"Prepared 3633 documents for embedding.\nPrepared 323 queries for embedding.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"print(\"Embedding documents... This may take a few minutes.\")\n\n# Embed all documents in the corpus\n# \"RETRIEVAL_DOCUMENT\" is used for items to be retrieved in a search system\ndoc_embeddings = embed_text(docs, model, \"RETRIEVAL_DOCUMENT\", batch_size=25) # Increased batch size for potentially faster processing\nprint(f\"Document embeddings generated. Shape: {doc_embeddings.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T20:47:27.600384Z","iopub.execute_input":"2025-05-22T20:47:27.600716Z","iopub.status.idle":"2025-05-22T20:52:22.796295Z","shell.execute_reply.started":"2025-05-22T20:47:27.600691Z","shell.execute_reply":"2025-05-22T20:52:22.795448Z"}},"outputs":[{"name":"stdout","text":"Embedding documents... This may take a few minutes.\nDocument embeddings generated. Shape: (3633, 768)\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# Create a FAISS index\n# IndexFlatL2 performs an exact search using L2 distance (Euclidean distance)\nindex = faiss.IndexFlatIP(doc_embeddings.shape[1])\n\n# Add the document embeddings to the FAISS index\nindex.add(doc_embeddings)\nprint(f\"FAISS index created and {index.ntotal} document embeddings added.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T20:52:22.797720Z","iopub.execute_input":"2025-05-22T20:52:22.798005Z","iopub.status.idle":"2025-05-22T20:52:22.825282Z","shell.execute_reply.started":"2025-05-22T20:52:22.797982Z","shell.execute_reply":"2025-05-22T20:52:22.824391Z"}},"outputs":[{"name":"stdout","text":"FAISS index created and 3633 document embeddings added.\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"### Example search to test the retrieval system","metadata":{}},{"cell_type":"code","source":"example_query = 'Is Caffeinated Tea Really Dehydrating?'\nprint(f\"Example query: '{example_query}'\")\n\n# Embed the example query\n# \"RETRIEVAL_QUERY\" is used for the search query itself\nexample_query_embedding = embed_text([example_query], model, 'RETRIEVAL_QUERY')\nprint(f\"Example query embedding shape: {example_query_embedding.shape}\")\n\n# Search the FAISS index for the top 3 most similar document\n# k=1 means we want the single most similar document\nk_results = 3\ndistances, retrieved_indices = index.search(example_query_embedding, k_results) #Index search returns a tuple containing two numpy array, distanes and indices.\n\n#retrieved_indices[0] --> This gives the array that represents the indices of the top 3 most similar vector.\n# Using the above indices, we can retrieve the original text chunk\n\nprint(f\"\\nTop {k_results} result(s) for the example query:\")\nfor i in range(k_results):\n    doc_index = retrieved_indices[0][i]\n    score = distances[0][i]\n    retrieved_doc_id = doc_ids[doc_index]\n    retrieved_doc_text = docs[doc_index]\n    print(f\"  Rank {i+1}:\")\n    print(f\"    Score (L2 Distance): {score:.2f}\")\n    print(f\"    Document ID: {retrieved_doc_id}\")\n    print(f\"    Text: \\\"{retrieved_doc_text[:250]}...\\\"\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T20:52:22.826342Z","iopub.execute_input":"2025-05-22T20:52:22.826572Z","iopub.status.idle":"2025-05-22T20:52:23.487800Z","shell.execute_reply.started":"2025-05-22T20:52:22.826554Z","shell.execute_reply":"2025-05-22T20:52:23.486837Z"}},"outputs":[{"name":"stdout","text":"Example query: 'Is Caffeinated Tea Really Dehydrating?'\nExample query embedding shape: (1, 768)\n\nTop 3 result(s) for the example query:\n  Rank 1:\n    Score (L2 Distance): 0.75\n    Document ID: MED-4331\n    Text: \"There is a belief that caffeinated drinks, such as tea, may adversely affect hydration. This was investigated in a randomised controlled trial. Healthy resting males (n 21) were recruited from the general population. Following 24 h of abstention from...\"\n  Rank 2:\n    Score (L2 Distance): 0.61\n    Document ID: MED-1853\n    Text: \"PURPOSE: To measure the pH, titratable acidity, fluoride concentration and erosive potential of brewed teas. METHODS: Bag teas were purchased to represent black, green, citrus, fruity, and floral tea flavors from Tulsi, Bigelow, HyVee, Tazo, and Yogi...\"\n  Rank 3:\n    Score (L2 Distance): 0.61\n    Document ID: MED-1645\n    Text: \"BACKGROUND: Tea consumption is associated with decreased cardiovascular risk. Flow-mediated dilatation (FMD) of the brachial artery is related to coronary endothelial function and it is an independent predictor of cardiovascular risk. Black tea has a...\"\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}